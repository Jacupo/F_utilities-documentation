\documentclass[class=book, crop=false]{standalone}
\usepackage[subpreambles=true]{standalone}
\usepackage{import}


%%%%INIZIO MIEI
\usepackage{amsmath,amsfonts,bm,hyperref,amssymb}
\newcommand{\expv}[1]{\left\langle #1 \right\rangle}
\newcommand{\floor}[1]{\lfloor #1 \rfloor}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\id}{\mathbb{I}}
\newcommand{\im}{{i\mkern1mu}}
\newcommand{\da}{^{\dag}}
\newcommand{\sx}{\sigma^x}
\newcommand{\sy}{\sigma^y}
\newcommand{\sz}{\sigma^z}
\newcommand{\ket}[1] {| #1 \rangle}
 \newcommand{\bra}[1] {\langle #1 |}
  \newcommand{\Tr}[1] {\mbox{Tr}\left[ #1 \right]}
  \DeclareMathOperator{\sech}{sech}
\newcount\colveccount
\newcommand*\colvec[1]{
        \global\colveccount#1
        \begin{pmatrix}
        \colvecnext
}
\def\colvecnext#1{
        #1
        \global\advance\colveccount-1
        \ifnum\colveccount>0
                \\
                \expandafter\colvecnext
        \else
                \end{pmatrix}
        \fi
}
\def\code#1{\texttt{#1}}
\usepackage{colortbl}
\definecolor{blue}{cmyk}{0.897, 0.393, 0, 0.0118}
\definecolor{green}{cmyk}{0.835, 0, 0.395, 0.0275}
\definecolor{red}{rgb}{0.992,0.498,0.486}
\usepackage{systeme}
\usepackage{mathtools}
\usepackage{float}
\usepackage{mathtools}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\usepackage[scaled]{beramono}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{listingsutf8}
\lstdefinelanguage{Julia}%
  {morekeywords={abstract,break,case,catch,const,continue,do,else,elseif,%
      end,export,false,for,function,global,immutable,import,importall,if,in,%
      macro,module,otherwise,quote,return,switch,true,try,type,typealias,%
      using,while},%
   sensitive=true,%
   alsoother={$},%
   morecomment=[l]\#,%
   morecomment=[n]{\#=}{=\#},%
   morestring=[s]{"}{"},%
   morestring=[m]{'}{'},%
}[keywords,comments,strings]%
\lstset{%
    language         = Julia,
    basicstyle       = \ttfamily,
    keywordstyle     = \bfseries\color{blue},
    stringstyle      = \color{magenta},
    commentstyle     = \color{green},
    showstringspaces = false,
    frame = single,
    framexleftmargin=15pt,
}
\usepackage{tikz-cd}
\tikzcdset{
    boxedcd/.style={
        every matrix/.append style={
            draw=red,
            thick,
            fill=yellow!50!white,
            rounded corners,
            #1
        },
    },
}
\newcommand*{\bfrac}[2]{\genfrac{}{}{0pt}{}{#1}{#2}}
\usepackage{multirow}
\usepackage{subcaption}
\newtheorem{theorem}{Theorem}[subsection]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{proposition}{Proposition}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}


\usepackage{tcolorbox}
\tcbuselibrary{theorems}
\newtcbtheorem[number within=subsection]{proposition}{\code{F\_utilities }}%
{colback=blue!5,colframe=blue!35!black,fonttitle=\bfseries}{th}

%%%%FINEMIEI



\begin{document}



\section{Extended calculations}
\subsection{Eigenvalues of $\Gamma$ and $H_{\alpha}$}
\label{appendix:Eigenvalues-Relations}
We consider the state $\rho=\frac{e^{-\vec{\alpha}^{\dagger}H \vec{\alpha}}}{Z}$, we diagonalise $H$ changing the basis to $\vec{\beta}=U^{\dagger}\vec{\alpha}$. Thus we have
\begin{equation}
\rho=\frac{e^{-\vec{\beta}^{\dagger}H_{D}\vec{\beta}}}{Z}=\frac{e^{-\sum_{k=1}^{N}\epsilon_{k}\left(b_{k}^{\dagger}b_{k}-b_{k}b_{k}^{\dagger}\right)}}{Z}.
\end{equation}

We change the basis of the correlation matrix too
\begin{equation}
\Gamma_{i,j}^{b}=\left(U^{\dagger}\Gamma U\right)_{i,j}=Tr\left[\rho\vec{\beta}_{i}\vec{\beta_{j}}^{\dagger}\right].
\end{equation}

Now we want to explicitly compute the elements of $\Gamma^{b}$. First of all we compute the normalisation constant

\begin{equation}
Z=Tr\left[e^{-\sum_{k=1}^{N}\epsilon_{k}\left(b_{k}^{\dagger}b_{k}-b_{k}b_{k}^{\dagger}\right)}\right] =2^N\prod_{k=1}^{N}\left(\cosh\left(\epsilon_{k}\right)\right).
\end{equation}

To compute the numerator part this equalities will result useful
\begin{itemize}
\item  For $x\neq y$

\begin{equation}
\begin{aligned}
Tr\left[e^{-\sum_{k=1}^{N}\epsilon_{k}\left(b_{k}^{\dagger}b_{k}-b_{k}b_{k}^{\dagger}\right)} b_{x}^{\dagger}b_{y}\right]	&  =\sum_{v\in\left\{ 0,1\right\} ^{N}}\langle v|e^{-\sum_{k=1}^{N}\epsilon_{k}\left(b_{k}^{\dagger}b_{k}-b_{k}b_{k}^{\dagger}\right)}b_{x}^{\dagger}b_{y}|v\rangle=\\
	&=\sum_{v\in\left\{ 0,1\right\} ^{N}}\langle v|e^{-\sum_{k=1}^{N}\epsilon_{k}\left(b_{k}^{\dagger}b_{k}-b_{k}b_{k}^{\dagger}\right)}|\tilde{v}\rangle=\\
	& =\sum_{v\in\left\{ 0,1\right\} ^{N}}e^{-\sum_{k=1}^{N}(-1)^{v_{k}+1}\epsilon_{k}}\langle v|\tilde{v}\rangle = 0
\end{aligned}
\end{equation}


\begin{equation}
Tr\left[e^{-\sum_{k=1}^{N}\epsilon_{k}\left(b_{k}^{\dagger}b_{k}-b_{k}b_{k}^{\dagger}\right)}b_{x}b_{y}^{\dagger}\right]=0
\end{equation}

\item $\forall x,y$

\begin{equation}
Tr\left[e^{-\sum_{k=1}^{N}\epsilon_{k}\left(b_{k}^{\dagger}b_{k}-b_{k}b_{k}^{\dagger}\right)}b_{x}b_{y}\right]=0
\end{equation}
\begin{equation}
Tr\left[e^{-\sum_{k=1}^{N}\epsilon_{k}\left(b_{k}^{\dagger}b_{k}-b_{k}b_{k}^{\dagger}\right)}b_{x}^{\dagger}b_{y}^{\dagger}\right]=0
\end{equation}

Thus the numerator can be explicitly written as

\begin{equation}
Tr\left[e^{-\sum_{k=1}^{N}\epsilon_{k}\left(b_{k}^{\dagger}b_{k}-b_{k}b_{k}^{\dagger}\right)}\vec{\alpha}_{i}\vec{\alpha_{j}}^{\dagger}\right]=
\end{equation}

\begin{equation*}
=\sum_{l=1}^{2N}\sum_{m=1}^{2N}U_{i,l}U_{m,j}^{\dagger}Tr\left[e^{-\sum_{k=1}^{N}\epsilon_{k}\left(b_{k}^{\dagger}b_{k}-b_{k}b_{k}^{\dagger}\right)}\vec{\beta}_{l}\vec{\beta_{m}}^{\dagger}\right]=
\end{equation*}

\begin{equation*}
=\sum_{l=1}^{N}U_{i,l}U_{l,j}^{\dagger}Tr\left[e^{-\sum_{k=1}^{N}\epsilon_{k}\left(b_{k}^{\dagger}b_{k}-b_{k}b_{k}^{\dagger}\right)}b_{l}^{\dagger}b_{l}\right]+\sum_{l=1}^{N}U_{i,l+N}U_{l+N,j}^{\dagger}Tr\left[e^{-\sum_{k=1}^{N}\epsilon_{k}\left(b_{k}^{\dagger}b_{k}-b_{k}b_{k}^{\dagger}\right)}b_{l}b_{l}^{\dagger}\right]=
\end{equation*}

\begin{equation*}
=\sum_{l=1}^{N}U_{i,l}U_{l,j}^{\dagger}e^{-\epsilon_{l}}\prod_{k\neq l}2\cosh(\epsilon_k))+\sum_{l=1}^{N}U_{i,l+N}U_{l+N,j}^{\dagger}e^{\epsilon_{l}}\prod_{k\neq l}2\cosh(\epsilon_k))
\end{equation*}

I can divide by Z and obtain

\begin{equation}
\begin{aligned}
\Gamma_{i,j} & =\sum_{l=1}^{N}U_{i,l}U_{l,j}^{\dagger}\frac{e^{-\epsilon_{l}}}{e^{\epsilon_{l}}+e^{-\epsilon_{l}}}+\sum_{l=1}^{N}U_{i,l+N}U_{l+N,j}^{\dagger}\frac{e^{\epsilon_{l}}}{e^{\epsilon_{l}}+e^{-\epsilon_{l}}}\\
 & =\sum_{l=1}^{N}U_{i,l}U_{l,j}^{\dagger}\frac{1}{1+e^{2\epsilon_{l}}}+\sum_{l=1}^{N}U_{i,l+N}U_{l+N,j}^{\dagger}\frac{1}{1+e^{-2\epsilon_{l}}}=\\
 & =(U\Gamma^{D}U^{\dagger})_{i,j}.
\end{aligned}
\end{equation}

\end{itemize}


So the same transformation U that moves to the free Hamiltonian $H_D$ is also the transformation that diagonalise the correlation matrix. The eigenvalues $\nu_{i}$ of the correlation matrix $\Gamma$ are related to the eigenvalues of the parent Hamiltonian $H$ by

\begin{equation}
\nu_{i}=\frac{1}{1+e^{2\epsilon_{i}}},
\end{equation}

\begin{equation}
\epsilon_{i}=\frac{1}{2}ln\left(\frac{1-\nu_{i}}{\nu_{i}}\right),
\end{equation}

since $\nu_{i}\in\left[0,1\right]$ the eigenvalues $\epsilon_{i}\text{\ensuremath{\in}[-\ensuremath{\infty},+\ensuremath{\infty}]}$.


\subsection{Purity}
\label{appendix:Purity}
From the previous paragraph we have:

\begin{equation}
Z^{2}=\prod_{k=1}^{N}\left(2\cosh\left(\epsilon_{k}\right)\right)^{2}
\end{equation}

and

\begin{equation}
Tr\left[e^{-\sum_{k=1}^{N}\epsilon_{k}\left(b_{k}^{\dagger}b_{k}-b_{k}b_{k}^{\dagger}\right)}\right]=\prod_{k=1}^{N}\left(2\cosh\left(2\epsilon_{k}\right)\right).
\end{equation}


Thus the purity is:

\begin{equation}
\mbox{Purity}=\prod_{k=1}^{N}\frac{1}{\sech(\epsilon_{k})+1}
\end{equation}


\subsection{Real Time Evolution}
\label{appendix:Real-Heisenberg-Evolution}
We want to compute the time evolution in the Heisenberg picture of the annihilation operator $b_k$ induced by the Hamiltonian $\hat{H} = \sum_{l=1}^{N} \epsilon_{l} (b\da_l b_l -b_l b\da_l) $.
First we simplify the expression exploiting the commuting terms 
\begin{align}
  b_k(t) &= e^{i\hat{H}t}b_ke^{-i\hat{H}t}=e^{ it\sum_{l=1}^{N} \epsilon_{l} (b\da_l b_l -b_l b\da_l)} b_k e^{it \sum_{l=1}^{N} \epsilon_{l} (b\da_k b_l -b_l b\da_l)}= \\
            &= e^{ it \epsilon_{k} (b\da_k b_k -b_k b\da_k)} b_k e^{it \epsilon_{k} (b\da_k b_k -b_k b\da_k)}.
\end{align}
Secondly applying B.C.H.1 (see B.C.H.1 in \ref{appendix:Formulas}) we obtain that
\begin{equation}
  b_k(t)  = \sum_{n=0}^{\infty} \frac{(i e_k t)^n}{n!}\underbrace{[b_k\da b_k-b_k b_k\da,\dots[v_k\da b_k-b_k b_k\da,}_{n}b_k\underbrace{]\dots]}{n},
\end{equation}
and using the fact that 
\begin{equation}
[b_k\da b_k-b_k b_k\da,b_k] = -2b_k,
\end{equation}
we obtain 
\begin{equation}
b_k(t)= \sum_{n=0}^{\infty} \frac{(2 i e_k t)^n}{n!}b_k = e^{-i2e_kt}b_k.
\end{equation}

\subsection{Circulant Matrices}
\label{appendix:Circulant-Matrices}
An $N \times N$ circulant matrix $C$ is a matric of the form
\begin{equation}
C=
\begin{pmatrix}
c_0		& c_1		& c_2		& \dots		& c_{N-1}	\\
c_{N-1}	& c_0		& c_1		& \dots		& c_{N-2}	\\
c_{N-2}	& c_{N-1}		& c_0		& \dots 		& c_{N-3}	\\
\vdots	& \vdots		& \vdots		& \ddots		&\vdots	\\
c_1		& c_2		& c_3		&\dots		&c_0		
\end{pmatrix}.
\end{equation} 
A circulant matrix is completely specified by the  \textit{circulant vector} $\vec{c}$, that is its first row. 
\begin{equation}
\vec{c} = \left( c_0, c_1, c_2, \dots, c_{N-1}\right).
\end{equation}
All the other rows of the matrix are cyclic permutations of $\vec{c}$ with offset increasing by one going down with the rows.\\
Since each descending diagonal from left to right is constant, circulant matrices are a special case of Toeplitz matrices.\\
Because of their special structure, circulant matrices are diagonalised by taking their Fourier transform.\\
Given a vector $\vec{v}$ of length $N$ its Fourier transform is expressed as $\vec{w}=W\vec{v}$, with $W$ defined as
\begin{equation}
W = \frac{1}{\sqrt{N}}\begin{pmatrix}
\omega			&\omega^2		&\omega^3		&\cdots	&\omega^{N-1} 		&1\\
\omega^2			&\omega^4		&\omega^6		&\cdots	&\omega^{2(N-1)}		&1\\ 
\omega^3			&\omega^6		&\omega^9		&\cdots	&\omega^{3(N-1)}		&1\\
\vdots			&\vdots			&\vdots			&\ddots	&\vdots				&1\\
\omega^{N-1}		&\omega^{2(N-1)}	&\omega^{3(N-1)}	&\cdots	&\omega^{(N-1)(N-1)}	&1\\
1				&1				&1				&1		&\cdots 				&1
\end{pmatrix},
\end{equation}
with $\omega = e^{-i\frac{2\pi}{N}}$.\\
The columns of $W$ are the normalised eigenvectors $|\lambda_i\rangle$ of every circulant matrix of dimension $N\times N$.\\
The corresponding eigenvalues depend on the specific circulant vector $\vec{c}$ specifying the circulant matrix and are given by 
\begin{equation}
\lambda_j = c_0 \omega^{j}+ c_1 \omega^{j} + c_2 \omega^{j2}+\dots +c_{N-2} \omega^{j(N-2)}+c_{N-1} \omega^{j(N-1)}.
\end{equation}


\subsection{Block diagonal form of skew-symmetric matrices}
\label{appendix:Shurd-Decomposition}
Let $h$ be a $N\times N$ skew-symmetric matrix of rank $2m$, where $N\geq2m$.\\
Then there exist a $N\times N$ unitary matrix $U$ such that  \cite{horn2012}
\begin{equation}
U^ThU = \begin{pmatrix} 0 & \lambda_1 \\ -\lambda_1 & 0 \end{pmatrix} \oplus \begin{pmatrix} 0 & \lambda_2 \\ -\lambda_2 & 0 \end{pmatrix} \oplus  \dots  \oplus \begin{pmatrix} 0 & \lambda_m \\ -\lambda_m & 0 \end{pmatrix} \oplus \hat{0}_{N-2m},
\end{equation}  
where $\hat{0}_{N-2m}$ is a $(N-2m)\times (N-2m)$ matrix with all elements equal to zero and where the real and positive-definite $\{\lambda_i\}_{i=1,m}$ are the singular values of $h$.\\
Since a skew-symmetric matrix $h$ is similar to its own transpose$h^T$, then $h$ and $h^T$ must have the same eigenvalues. Thus, the eigenvalues of a skew-symmetric matrix of even dimension will always come in pairs $\pm \tilde{\lambda}$ (for the case of odd dimension there will be an unpaired eigenvalue equal to $0$). 

\subsection{Power method algorithm}
\label{sec:Power-Method}
The power method algorithm is based on the following idea. Suppose we want to find the biggest eigenvalue  $\lambda_1$ and its associated eigenvector $\ket{\lambda_1}$ of a diagonalisable matrix $H$. We will consider the eigenvalues of $H$ to be ordered as $\lambda_1 > \lambda_2 \geq \lambda_3 \geq \dots$. We start by choosing a random vector $\ket{v^{[0]}}$. We define the iterative algorithm
\begin{equation}
\ket{v^{[n+1]}} = \frac{H\ket{v^{[n]}}}{\norm{H\ket{v^{[n]}}}},
\end{equation}
where $\norm{\ket{v}}$ is the norm of $\ket{v}$. Starting with $\ket{v^{[0]}}$, we expect that, if $\bk{\lambda_1}{v^{[0]}}\neq 0$ and $\lambda_1$ is not degenerate, for $n$ sufficiently big, $\ket{v^{[n]}} \sim \ket{\lambda_1}$.
The fact that this algorithm converges towards $\ket{\lambda_1}$ can be easily proved by expanding $\ket{v^{[0]}}$ on the eigenbasis $\{\ket{\lambda_i}\}_i$ of $H$
\begin{equation}
\ket{v^{[0]}} = c_1 \ket{\lambda_1} +c_2 \ket{\lambda_2}+\dots,
\end{equation}
with $c_i = \bk{\lambda_i}{v^{[0]}}$ and thus $c_1 \neq 0$ because of the assumption $\bk{\lambda_1}{v^{[0]}}\neq 0$.
Now applying $H$ to $\ket{v^{[0]}}$ for $n$ times returns
\begin{equation}
H^n \ket{v^{[0]}} = c_1 \lambda_1^n \left( \ket{\lambda_1}+ \frac{c_2}{c_1} (\frac{\lambda_2}{\lambda_1})^2 \ket{\lambda_2}+\dots \right).
\end{equation}
Since $\lambda_1$ is the biggest eigenvalue we have that $(\frac{\lambda_i}{\lambda_1})^n \to 0$ with $n \to \infty$ for all $i\neq 1$. Because of this, we obtain that in the limit for $n \to \infty$, taking care of the normalisation,  $H^n \ket{v^{[0]}} \to \ket{\lambda_1}$.\\
The convergence of this method is slow (it is geometric with ratio $\left|\frac{\lambda_2}{\lambda_1} \right|$) and it becomes slower as $\lambda_2 \to \lambda_1$. \\
We note here the importance of the value of the difference $|\lambda_1-\lambda_2|$.\\

In condensed matter one is often interested in computing the ground state energy $E_0$ of a Hamiltonian $H$, that is the smallest eigenvalue of $H$. By adding a sufficiently big number to the Hamiltonian, one obtains that the smallest eigenvalue of $H$ corresponds to the eigenvalue with the smallest magnitude. In order to compute the smallest eigenvalue in magnitude of $H$ one can use the inverse power method \cite{grinfeld2015} that fundamentally is the power method applied to $H^{-1}$. In this case the algorithm will converge geometrically with ratio $\frac{E_0}{E_1}$, where  $E_1$ is the second smallest eigenvalue of the Hamiltonian $H$. If $E_1-E_0 = 0$ then the algorithm will not converge.\\
Because of its importance, the difference between the two lowest eigenvalues of an Hamiltonian (that is the difference between the ground state energy and the first excited state energy) has a specific name and it is called \textit{Hamiltonian Gap} or \textit{spectral gap} often denoted by $\Delta E$. In particular, definining a family of Hamiltonians dependendent on the parameter $N$ (the dimension of the system), we call \textit{gapless Hamiltonians} those Hamiltonians for wich the Hamiltonian Gap $\to 0$ in the thermodynamics limit $N \to \infty$, and  we call \textit{gapped Hamiltonians} those Hamiltonians for which the spectral gap remains positive in the thermodynamic limit.

\subsection{Jordan-Wigner transformation}
\label{appendix:Jordan-Wigner}
The Jordan-Wigner transformation, introduced in the original paper \cite{jordan1928}, is a transformation that maps spin-$\tfrac{1}{2}$ systems to fermionic systems. \\
Suppose we have a system of $N$ spins-$\tfrac{1}{2}$ with the usual Pauli matrices $\sigma_j^x$, $\sigma_j^y$ and $\sigma_j^z$ acting on the $j$-th spin of the system
The Jordan-Wigner transformation defines the operator $a_j$ as
\begin{equation}
\label{eq:Pauli-To-Annihilation}
a_j = -\left(\otimes_{k=1}^{j-1}\sigma^z_k \right)\otimes \sigma_j^+\left(\otimes_{k=j+1}^{N} \id_k \right),
\end{equation}
where $\sigma_j^{\pm}=\tfrac{\sigma^x_j\pm \im \sigma_j^y}{2}$ and $\id_j$ is the identity acting on the $j$-th spin. 
Taking the adjoint obtains
\begin{equation}
\label{eq:Pauli-To-creation}
a_j\da = -\left(\otimes_{k=1}^{j-1}\sigma^z_k \right)\otimes \sigma_j^-\left(\otimes_{k=j+1}^{N} \id_k \right).
\end{equation}
Computing the anticommutator of these two operators we notice that they obey the CAR, thus using this transformation for every site $j$ we are able to build a legitimate set of Dirac fermionic operators starting from a set of Pauli matrices.\\
Knowing the expression for the creation and annihilation operators, we can easily find the mapping of the single site occupation operator in term of Pauli operators:
\begin{equation}
a_j\da a_j =  \left(\otimes_{k=1}^{j-1} \id_k \right)\otimes \frac{\id_j-\sigma_j^z}{2}\left(\otimes_{k=j+1}^{N} \id_k \right).
\end{equation}
Finally there are two important remarks.
We notice that the mapping from spins to fermions is not local, in the sense that equation \ref{eq:Pauli-To-Annihilation} maps a string of Pauli operators acting non trivially on $j$ spins to a Dirac operator local only on site $j$. \\
We even notice that in the definition of the annihilation operator \ref{eq:Pauli-To-Annihilation} it is encoded some information on the geometrical structure of the spin system, in particular it is encoded the distance of site $j$ from the border.\\
When using the Jordan-Wigner transformation one has to be careful about these two observations.\\

In the main text we are interested in mapping the transverse field Ising Hamiltonian to a fermionic system, thus we need the inverse Jordan-Wigner transformation.
We have that the Pauli operator $ \sigma_j^z$ is easily mapped to fermionic annihilation and creation operators as
\begin{equation}
\label{eq:Pauli_Z-To-Dirac}
\sigma_j^z = a_j a_j\da-a_j\da a_j = 1-2a_j\da a_j.
\end{equation}
We see that for this transformation local spin operators are mapped to local fermionic operators. We know nonetheless that the Jordan-Wigner transformation does not preserve locality in general, indeed we have that the Pauli operators $\sigma_j^x$ and $\sigma_j^y$ maps to fermionic operators as
\begin{align}
\sigma_j^x = -\left(\otimes_{k=1}^{j-1}\sigma^z_k \right)\otimes (a_j+a_j\da)\left(\otimes_{k=j+1}^{N} \id_k \right) \nonumber \\
\sigma_j^y = \im \left(\otimes_{k=1}^{j-1}\sigma^z_k \right)\otimes (a_j\da-a_j)\left(\otimes_{k=j+1}^{N} \id_k \right),
\end{align}
where for each $\sigma_k^z$ one should use the substitution \eqref{eq:Pauli_Z-To-Dirac}. \\
Fortunately, if we consider the product of Pauli operators, as for example are the spin-spin interactions in the TFI model we have 
\begin{align}
 \sigma_j^x\sigma_{j+1}^x = (a_j^{\dag}-a_j)(a_{j+1}+a_{j+1}^{\dag}), \nonumber \\
 \sigma_j^y\sigma_{j+1}^y = -(a_j^{\dag}+a_j)(a_{j+1}^{\dag}-a_{j+1}), \nonumber \\
\sigma_j^x\sigma_{j+1}^y = \im (a_j^{\dag}-a_j)(a_{j+1}^{\dag}-a_{j+1}),\nonumber \\
 \sy_j\sx_{j+1} = \im (a_j\da+a_j)(a_{j+1}\da+a_{j+1}),
\end{align}
nearest neighbour interactions are mapped to nearest neighbour interactions.\\
It easy to see that an interaction of this kind between two arbitrary spins at site $j$ and $k$ will map to a string of Dirac operators acting non trivially on all sites between $j$ and $k$. \\

We have seen that the Jordan-Wigner transformation defines an isomorphism from a system of $n$ fermions to a system of $n$ spins. One should ask why we cannot completely identify spin systems with fermionic systems or vice versa.
To answer to this question we remind that, as specified above, the Jordan-Wigner mapping does not preserve the locality. 
One of the consequence of this fact is that the procedure of partial tracing does not generally commute with the Jordan-Wigner mapping \cite{friis2013a,friis2016}.
Consider for example a state of $N$ fermions $\rho_{AB}$ defined on a system divided in two complementary partitions $A$ and $B$. We map $\rho_{AB}$ with a Jordan-Wigner transformation to a state $\tilde{\rho}_{AB}$ of $N$ spins. Now we consider the reduced states $\rho_A$ and $\tilde{\rho}_A$ on partition $A$ of the states $\rho_{AB}$ and $\tilde{\rho}_{AB}$. If, using a Jordan-Wigner transformation, we map the state $\rho_{A}$ to the spin state $\tilde{\tilde{\rho}}_{A}$, we will generally have that $\tilde{\rho}_{A}\neq \tilde{\tilde{\rho}}_{A}$ as shown schematically in figure \ref{fig:Friis-Fermions-Spins}.\\

  \centerline{\label{fig:Friis-Fermions-Spins}
\includegraphics[width=0.5\textwidth]{figure/friis-rdm.pdf} }
  \captionof{figure}{The mapping of the reduced state is different from the reduced state of the mapping \cite{friis2016}}

For a detailed and very well explained treatment of this question see \cite{friis2016}.
We end this subsection pointing out that, the fact that the well defined trace for fermionic system is not consistent with the mapping between fermions and qubits, leads to many interesting questions on entanglement in fermionic systems, see e.g.  \cite{li2001,schliemann2001,wolf2006,banuls2007,sindici2018,becher2020a}

 \section{Useful relations}
 \subsection{Pauli Matrices}
 \begin{enumerate}
  \item  $\sigma^+ = \begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix}$, $\sigma^-=\begin{pmatrix} 0 & 0 \\ 1 & 0 \end{pmatrix}$, $\sigma^z=\begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix}$, $\sigma^y=\begin{pmatrix} 0 & -\im \\ \im & 0 \end{pmatrix}$, $\sigma^x=\begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix}$, $\ket{+}_x= \frac{1}{\sqrt{2}}\colvec{2}{1}{1}$, $\ket{-}_x= \frac{1}{\sqrt{2}}\colvec{2}{1}{-1}$, $\ket{+}_y= \frac{1}{\sqrt{2}}\colvec{2}{1}{\im}$, $\ket{-}_y= \frac{1}{\sqrt{2}}\colvec{2}{1}{-\im}$, $\ket{0_{-}}_z= \colvec{2}{0}{1}$, $\ket{1_{+}}_z=\colvec{2}{1}{0}$
 \item $\sigma^z \sigma^- = -\sigma^-$
 \item $\sigma^z \sigma^+ = \sigma^+$
 \item $\sigma^- \sigma^z = \sigma^-$
 \item $\sigma^+ \sigma^z = -\sigma^+$
 \item $\sigma^+ \sigma^- = \frac{\sigma^z+\id}{2}$
  \item $\sigma^- \sigma^+ = \frac{\id-\sigma^z}{2}$
 \end{enumerate}
 \subsection{Operators obeying CAR}
 \label{appendix:fermionic_operators}
 \begin{enumerate}
 \item $\{a_i,a\da_j\} = \id \delta_{i,j}$ \qquad $\{a_i,a_j \}=\{a_i^{\dagger},a_{j}^{\dagger} \} = 0$
 \item $a_ia_j=-a_ja_i$;\qquad $a_i^{\dagger}a_j^{\dagger} = -a_{j}^{\dagger}a_i^{\dagger}$
 \item $a^2_i=\left(a\da_j\right)^2=0$
 \item $a_ia_j^{\dagger}=\delta_{i,j}-a_j^{\dagger}a_i$
 \item $a_ia_j=\frac{a_ia_j-a_ja_i}{2}$
 \item $a_ia_j^{\dagger}=\frac{a_ia_j^{\dagger}-a_j^{\dagger}a_i}{2}+\frac{\delta_{i,j}}{2}$
  \item $a_i^{\dagger}a_j=\frac{a_i^{\dagger}a_j-a_ja_i^{\dagger}}{2}+\frac{\delta_{i,j}}{2}$
 \end{enumerate}
Commutators
 \begin{enumerate}
  \item $[a_i^{\dagger},a_j]=\delta_{i,j}-2a_ja_i^{\dagger}=a_i^{\dagger}a_j-\delta_{i.j}$
  \item $[a_i,a_j^\dagger]=\delta_{i,j}-2a_j^{\dagger}a_i=a_i a_j^{\dagger}-\delta_{i,j}$
  \item $[a_i,a_j]=2a_i a_j$
  \item $[a_i^{\dagger},a_j^{\dagger}]=2a_i^{\dagger}a_j^{\dagger}$
 \end{enumerate}
 Majorana operators
 \begin{enumerate}
\item $x_{i}^{2}=p_{i}^{2}=\frac{1}{2}$
\item $a^{\dagger}a=\frac{i}{2}\left(xp-px\right)+\frac{1}{2}=ixp+\frac{1}{2}$
\item $aa^{\dagger}=\frac{i}{2}\left(px-xp\right)+\frac{1}{2}=ipx+\frac{1}{2}$
\item $xp=-\frac{i}{2}\left(a^{\dagger}a-aa^{\dagger}\right)=-i\left(a^{\dagger}a-\frac{1}{2}\right)$
\end{enumerate}

 \subsection{Jordan-Wigner Transformations}
 \label{Appendix:Jordan-Wigner-Formulas}
 \paragraph{spinless fermions $\rightarrow$ spins}
 \begin{enumerate}
 \item $a_j=-\bigotimes_{k=1}^{j-1}\sigma_k^z\otimes\sigma_j^-\bigotimes_{k=j+1}^N\mathbb{I}_k$
 \item $a_j^{\dag}=-\bigotimes_{k=1}^{j-1}\sigma_k^z\otimes\sigma_j^+\bigotimes_{k=j+1}^N\mathbb{I}_k$
  \item $a_j^{\dag}a_j=\otimes_{k=1}^{j-1} \id_k \otimes \frac{\sigma_j^z+\id_j}{2}\otimes_{k=j+1}^{N} \id_k $
 \end{enumerate}
 \paragraph{spins $\rightarrow$ spinless fermions}
 \begin{enumerate}
 \item $\sigma_j^z = a_j^{\dag} a_j-a_j a_j^{\dag}$
 \item $\sigma_j^x = -\bigotimes_{k=1}^{j-1}\sigma_j^z\otimes(a_j+a_j^{\dag})\bigotimes_{k=j+1}^{N}\id_j$
 \item $\sigma_j^x = \im \bigotimes_{k=1}^{j-1}\sigma_j^z\otimes(a_j^{\dag}-a_j)\bigotimes_{k=j+1}^{N}\id_j$
 \item $\sigma_j^x\sigma_{j+1}^x = (a_j^{\dag}-a_j)(a_{j+1}+a_{j+1}^{\dag})$
 \item $\sigma_j^y\sigma_{j+1}^y = -(a_j^{\dag}+a_j)(a_{j+1}^{\dag}-a_{j+1}) $
 \item $\sigma_j^x\sigma_{j+1}^y = \im (a_j^{\dag}-a_j)(a_{j+1}^{\dag}+a_{j+1})$
 \item $\sy_j\sx_{j+1} = \im (a_j\da+a_j)(a_{j+1}\da+a_{j+1})$
 \end{enumerate}
 
 
\subsection{Formulas}
\label{appendix:Formulas}
\begin{enumerate}
\item B.C.H. 1: $e^Ae^B=e^{Z}$ with $Z=A+B+\frac{1}{2}\left[A,B \right]+\frac{1}{12}\left[A,\left[A,B\right]\right]+\frac{1}{12}\left[B,\left[A,B\right]\right]+\dots \mbox{higher commutators of A and B}$
\item B.C.H 2: $e^ABe^{-A} = \sum_{n=0}^{\infty} \frac{1}{n!}\underbrace{[A,\dots [A}_{n},B\underbrace{] \dots ]}_{n}$ where $[A,B]=AB-BA$.
\item B.C.H 3: $e^ABe^{A} = \sum_{n=0}^{\infty} \frac{1}{n!}\underbrace{\{A,\dots \{A}_{n},B\underbrace{\} \dots \}}_{n}$ where $\{A,B\}=AB+BA$.
\item Kronecker Delta: $\delta_{n,m} = \frac{1}{N} \sum_{k=1}^{N} e^{i \frac{2 \pi}{N}k(n-m)}$.
\end{enumerate}





%\bibliography{QFH}
%\bibliographystyle{ieeetr}

\end{document}





%Questo qua sotto Ã¨ se voglio importare un tex in questo subtex
%\begin{figure}[ht]
%
%\subimport{../}{diagram.tex}
%
%\label{fig:tikzexample}
%\caption{A nice simple diagram}
%\end{figure}
